import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, global_mean_pool
from torch_geometric.data import Data, DataLoader
import numpy as np
import pandas as pd
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import networkx as nx
from datetime import datetime, timedelta
import pickle

class DiffusionNet(nn.Module):
    """
    DiffusionNet: Temporal Graph Neural Network for Cross-Language Translation Flow Prediction
    
    This model combines temporal graph neural networks with macroeconomic features
    to predict translation delays between language pairs on Wikipedia.
    """
    
    def __init__(self, num_node_features, num_macro_features, hidden_dim=64, num_layers=3, dropout=0.3):
        super(DiffusionNet, self).__init__()
        
        self.num_layers = num_layers
        self.hidden_dim = hidden_dim
        self.dropout = dropout
        
        # Graph Neural Network layers
        self.gnn_layers = nn.ModuleList()
        self.gnn_layers.append(GCNConv(num_node_features, hidden_dim))
        
        for i in range(num_layers - 1):
            self.gnn_layers.append(GCNConv(hidden_dim, hidden_dim // (2**i)))
        
        # Prediction head
        final_gnn_dim = hidden_dim // (2**(num_layers-2)) if num_layers > 1 else hidden_dim
        self.prediction_head = nn.Sequential(
            nn.Linear(final_gnn_dim * 2 + num_macro_features, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 2, 1)
        )
        
        # Temporal decay parameter (learnable)
        self.temporal_decay = nn.Parameter(torch.tensor(0.1))
        
    def compute_temporal_weights(self, edge_index, edge_timestamps, current_time):
        """
        Compute temporal edge weights based on exponential decay
        
        Args:
            edge_index: Edge indices [2, num_edges]
            edge_timestamps: Timestamps for each edge [num_edges]
            current_time: Current timestamp for weight computation
            
        Returns:
            edge_weights: Temporal weights for each edge [num_edges]
        """
        time_diffs = current_time - edge_timestamps
        edge_weights = torch.exp(-self.temporal_decay * time_diffs)
        return edge_weights
    
    def forward(self, x, edge_index, edge_timestamps, current_time, source_indices, target_indices, macro_features):
        """
        Forward pass of DiffusionNet
        
        Args:
            x: Node features [num_nodes, num_node_features]
            edge_index: Edge indices [2, num_edges]
            edge_timestamps: Edge timestamps [num_edges]
            current_time: Current time for temporal weight computation
            source_indices: Indices of source nodes for prediction [batch_size]
            target_indices: Indices of target nodes for prediction [batch_size]
            macro_features: Macroeconomic features for target languages [batch_size, num_macro_features]
            
        Returns:
            predictions: Predicted translation delays [batch_size]
        """
        # Compute temporal edge weights
        edge_weights = self.compute_temporal_weights(edge_index, edge_timestamps, current_time)
        
        # Graph Neural Network forward pass
        h = x
        for i, gnn_layer in enumerate(self.gnn_layers):
            h = gnn_layer(h, edge_index, edge_weights)
            if i < len(self.gnn_layers) - 1:
                h = F.relu(h)
                h = F.dropout(h, p=self.dropout, training=self.training)
        
        # Extract source and target embeddings
        source_embeddings = h[source_indices]  # [batch_size, hidden_dim]
        target_embeddings = h[target_indices]  # [batch_size, hidden_dim]
        
        # Concatenate embeddings and macro features
        combined_features = torch.cat([
            source_embeddings,
            target_embeddings,
            macro_features
        ], dim=1)
        
        # Prediction head
        predictions = self.prediction_head(combined_features).squeeze(-1)
        
        return predictions

class TemporalGraphDataset:
    """
    Dataset class for temporal graph data with translation events
    """
    
    def __init__(self, translation_events_df, language_features_df):
        self.events_df = translation_events_df
        self.lang_features_df = language_features_df
        
        # Create language to index mapping
        self.lang_to_idx = {lang: idx for idx, lang in enumerate(language_features_df.index)}
        self.idx_to_lang = {idx: lang for lang, idx in self.lang_to_idx.items()}
        
        # Prepare node features
        self.node_features = self._prepare_node_features()
        
        # Prepare macro features
        self.macro_scaler = StandardScaler()
        macro_cols = ['gdp_per_capita', 'internet_penetration', 'speakers']
        self.macro_features = self.macro_scaler.fit_transform(language_features_df[macro_cols])
        
    def _prepare_node_features(self):
        """Prepare node features for each language"""
        # Simple one-hot encoding for languages
        num_languages = len(self.lang_to_idx)
        features = torch.eye(num_languages)
        return features
    
    def create_temporal_graph(self, events_subset, current_time):
        """
        Create a temporal graph for a subset of events
        
        Args:
            events_subset: DataFrame with translation events up to current_time
            current_time: Current timestamp
            
        Returns:
            Data object for PyTorch Geometric
        """
        # Create edges from translation events
        edge_list = []
        edge_timestamps = []
        
        for _, event in events_subset.iterrows():
            source_idx = self.lang_to_idx[event['source_lang']]
            target_idx = self.lang_to_idx[event['target_lang']]
            
            edge_list.append([source_idx, target_idx])
            edge_timestamps.append(event['translation_time'])
        
        if len(edge_list) == 0:
            # Handle empty graph case
            edge_index = torch.empty((2, 0), dtype=torch.long)
            edge_timestamps = torch.empty(0)
        else:
            edge_index = torch.tensor(edge_list, dtype=torch.long).t()
            edge_timestamps = torch.tensor(edge_timestamps, dtype=torch.float)
        
        # Convert current_time to tensor
        current_time_tensor = torch.tensor(float(current_time), dtype=torch.float)
        
        return Data(
            x=self.node_features,
            edge_index=edge_index,
            edge_timestamps=edge_timestamps,
            current_time=current_time_tensor
        )

class DiffusionNetTrainer:
    """
    Training and evaluation class for DiffusionNet
    """
    
    def __init__(self, model, dataset, device='cpu'):
        self.model = model.to(device)
        self.dataset = dataset
        self.device = device
        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)
        self.criterion = nn.MSELoss()
        
    def train_epoch(self, train_events, temporal_reg_weight=0.01):
        """Train for one epoch"""
        self.model.train()
        total_loss = 0
        num_batches = 0
        
        # Group events by time periods for batch processing
        train_events = train_events.sort_values('translation_time')
        
        for i in range(0, len(train_events), 64):  # Batch size 64
            batch_events = train_events.iloc[i:i+64]
            
            if len(batch_events) == 0:
                continue
                
            # Create temporal graph up to the latest event in batch
            max_time = batch_events['translation_time'].max()
            historical_events = train_events[train_events['translation_time'] <= max_time]
            
            graph_data = self.dataset.create_temporal_graph(historical_events, max_time)
            graph_data = graph_data.to(self.device)
            
            # Prepare batch data
            source_indices = torch.tensor([
                self.dataset.lang_to_idx[lang] for lang in batch_events['source_lang']
            ], dtype=torch.long).to(self.device)
            
            target_indices = torch.tensor([
                self.dataset.lang_to_idx[lang] for lang in batch_events['target_lang']
            ], dtype=torch.long).to(self.device)
            
            macro_features = torch.tensor([
                self.dataset.macro_features[self.dataset.lang_to_idx[lang]] 
                for lang in batch_events['target_lang']
            ], dtype=torch.float).to(self.device)
            
            targets = torch.tensor(batch_events['delay_days'].values, dtype=torch.float).to(self.device)
            
            # Forward pass
            predictions = self.model(
                graph_data.x,
                graph_data.edge_index,
                graph_data.edge_timestamps,
                graph_data.current_time,
                source_indices,
                target_indices,
                macro_features
            )
            
            # Compute loss
            mse_loss = self.criterion(predictions, targets)
            
            # Temporal regularization (simplified)
            temporal_reg = temporal_reg_weight * torch.norm(self.model.temporal_decay)
            
            total_loss_batch = mse_loss + temporal_reg
            
            # Backward pass
            self.optimizer.zero_grad()
            total_loss_batch.backward()
            self.optimizer.step()
            
            total_loss += total_loss_batch.item()
            num_batches += 1
        
        return total_loss / max(num_batches, 1)
    
    def evaluate(self, test_events):
        """Evaluate model on test events"""
        self.model.eval()
        all_predictions = []
        all_targets = []
        
        test_events = test_events.sort_values('translation_time')
        
        with torch.no_grad():
            for i in range(0, len(test_events), 64):
                batch_events = test_events.iloc[i:i+64]
                
                if len(batch_events) == 0:
                    continue
                
                # Create temporal graph up to batch time
                max_time = batch_events['translation_time'].max()
                historical_events = test_events[test_events['translation_time'] <= max_time]
                
                graph_data = self.dataset.create_temporal_graph(historical_events, max_time)
                graph_data = graph_data.to(self.device)
                
                # Prepare batch data
                source_indices = torch.tensor([
                    self.dataset.lang_to_idx[lang] for lang in batch_events['source_lang']
                ], dtype=torch.long).to(self.device)
                
                target_indices = torch.tensor([
                    self.dataset.lang_to_idx[lang] for lang in batch_events['target_lang']
                ], dtype=torch.long).to(self.device)
                
                macro_features = torch.tensor([
                    self.dataset.macro_features[self.dataset.lang_to_idx[lang]] 
                    for lang in batch_events['target_lang']
                ], dtype=torch.float).to(self.device)
                
                targets = batch_events['delay_days'].values
                
                # Forward pass
                predictions = self.model(
                    graph_data.x,
                    graph_data.edge_index,
                    graph_data.edge_timestamps,
                    graph_data.current_time,
                    source_indices,
                    target_indices,
                    macro_features
                )
                
                all_predictions.extend(predictions.cpu().numpy())
                all_targets.extend(targets)
        
        # Compute metrics
        mae = mean_absolute_error(all_targets, all_predictions)
        rmse = np.sqrt(mean_squared_error(all_targets, all_predictions))
        r2 = r2_score(all_targets, all_predictions)
        
        return {
            'mae': mae,
            'rmse': rmse,
            'r2': r2,
            'predictions': all_predictions,
            'targets': all_targets
        }

def main():
    """Main training and evaluation script"""
    # Load data
    events_df = pd.read_csv('data/translation_events.csv')
    lang_features_df = pd.read_csv('data/language_characteristics.csv', index_col=0)
    
    # Convert timestamps
    events_df['creation_time'] = pd.to_datetime(events_df['creation_time'])
    events_df['translation_time'] = pd.to_datetime(events_df['translation_time'])
    
    # Create temporal splits
    train_events = events_df[events_df['translation_time'] < '2021-01-01']
    val_events = events_df[(events_df['translation_time'] >= '2021-01-01') & 
                          (events_df['translation_time'] < '2023-01-01')]
    test_events = events_df[events_df['translation_time'] >= '2023-01-01']
    
    print(f"Train events: {len(train_events)}")
    print(f"Validation events: {len(val_events)}")
    print(f"Test events: {len(test_events)}")
    
    # Create dataset
    dataset = TemporalGraphDataset(events_df, lang_features_df)
    
    # Initialize model
    num_node_features = len(lang_features_df)
    num_macro_features = 3  # GDP, internet penetration, speakers
    
    model = DiffusionNet(
        num_node_features=num_node_features,
        num_macro_features=num_macro_features,
        hidden_dim=64,
        num_layers=3,
        dropout=0.3
    )
    
    # Initialize trainer
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    trainer = DiffusionNetTrainer(model, dataset, device)
    
    # Training loop
    best_val_mae = float('inf')
    patience = 20
    patience_counter = 0
    
    for epoch in range(200):
        train_loss = trainer.train_epoch(train_events)
        
        if epoch % 10 == 0:
            val_results = trainer.evaluate(val_events)
            print(f"Epoch {epoch}: Train Loss = {train_loss:.4f}, Val MAE = {val_results['mae']:.4f}")
            
            if val_results['mae'] < best_val_mae:
                best_val_mae = val_results['mae']
                patience_counter = 0
                # Save best model
                torch.save(model.state_dict(), 'code/best_diffusionnet_model.pth')
            else:
                patience_counter += 1
                
            if patience_counter >= patience:
                print("Early stopping triggered")
                break
    
    # Load best model and evaluate on test set
    model.load_state_dict(torch.load('code/best_diffusionnet_model.pth'))
    test_results = trainer.evaluate(test_events)
    
    print("\nFinal Test Results:")
    print(f"MAE: {test_results['mae']:.2f} days")
    print(f"RMSE: {test_results['rmse']:.2f} days")
    print(f"RÂ²: {test_results['r2']:.3f}")
    
    # Save results
    results_dict = {
        'test_mae': test_results['mae'],
        'test_rmse': test_results['rmse'],
        'test_r2': test_results['r2'],
        'predictions': test_results['predictions'],
        'targets': test_results['targets']
    }
    
    with open('results/diffusionnet_final_results.pkl', 'wb') as f:
        pickle.dump(results_dict, f)
    
    print("Training completed and results saved!")

if __name__ == "__main__":
    main()

